{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38cc1e85-b091-4d3d-84e7-4d6eb59cfe4b",
   "metadata": {},
   "source": [
    "# 3. Mini-batch & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666938ab-353c-426d-bccf-6b4cc1b7b5e2",
   "metadata": {},
   "source": [
    "## 3-1. Mini-batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60bae29-d202-4c92-8c67-0e0ebaf1cda4",
   "metadata": {},
   "source": [
    "> 데이터셋의 크기가 클 때, 모든 데이터를 한 epoch에 사용하는 것은 계산량이 많아 시간에 비효율적일 수 있다.  \n",
    "따라서 한 epoch에 사용될 데이터셋의 양을 의미하는 배치 사이즈를 조정하여 경사 하강법을 적용하면  \n",
    "파라미터가 최적값에 수렴하는 과정에서 값이 조금 해매기도 하지만 훈련 속도가 빠르다는 장점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7aa13e-532d-4517-8c96-81c3d47391af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3-2. DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e23669-a35a-4d0e-b380-cd279813a1b1",
   "metadata": {},
   "source": [
    "> Pytorch에는 데이터를 쉽게 다룰 수 있도록 Dataset과 DataLoader를 제공한다.  \n",
    "이를 사용하면 mini-batch와 데이터 셔플, 병렬 처리까지 간단하게 수행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24339dd-63c4-4ec7-8631-881639795dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e28ff405-d02b-4b21-b321-621f13817688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a705f2-b04f-493a-9e14-6857efb9ca1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TensorDataset에 넣을 텐서 데이터셋을 준비하고,\n",
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  90], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "\n",
    "# dataset 변수에 저장한다.\n",
    "dataset = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010560f9-f0e5-4a25-b678-83d55e3134a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "024fb520-dad7-48a1-a847-a7a914b3d35f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd12a64-0deb-425f-b1c9-e33e9f4162a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.5205,  0.3613, -0.4948]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2580], requires_grad=True)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(model.parameters()))\n",
    "hasattr(model.parameters(), '__iter__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e04be0-e928-4b4f-ab30-75719750dbd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Loss: 19478.240234\n",
      "Epoch    0/20 Batch 2/3 Loss: 7023.405762\n",
      "Epoch    0/20 Batch 3/3 Loss: 1139.117554\n",
      "Epoch    1/20 Batch 1/3 Loss: 597.621887\n",
      "Epoch    1/20 Batch 2/3 Loss: 282.262634\n",
      "Epoch    1/20 Batch 3/3 Loss: 129.153992\n",
      "Epoch    2/20 Batch 1/3 Loss: 17.224823\n",
      "Epoch    2/20 Batch 2/3 Loss: 7.098171\n",
      "Epoch    2/20 Batch 3/3 Loss: 0.324682\n",
      "Epoch    3/20 Batch 1/3 Loss: 4.572136\n",
      "Epoch    3/20 Batch 2/3 Loss: 1.105261\n",
      "Epoch    3/20 Batch 3/3 Loss: 2.682446\n",
      "Epoch    4/20 Batch 1/3 Loss: 2.677387\n",
      "Epoch    4/20 Batch 2/3 Loss: 4.604275\n",
      "Epoch    4/20 Batch 3/3 Loss: 0.004873\n",
      "Epoch    5/20 Batch 1/3 Loss: 1.772445\n",
      "Epoch    5/20 Batch 2/3 Loss: 2.818352\n",
      "Epoch    5/20 Batch 3/3 Loss: 3.113338\n",
      "Epoch    6/20 Batch 1/3 Loss: 1.860489\n",
      "Epoch    6/20 Batch 2/3 Loss: 2.754703\n",
      "Epoch    6/20 Batch 3/3 Loss: 3.011710\n",
      "Epoch    7/20 Batch 1/3 Loss: 1.785374\n",
      "Epoch    7/20 Batch 2/3 Loss: 3.096839\n",
      "Epoch    7/20 Batch 3/3 Loss: 3.643802\n",
      "Epoch    8/20 Batch 1/3 Loss: 1.218984\n",
      "Epoch    8/20 Batch 2/3 Loss: 4.890136\n",
      "Epoch    8/20 Batch 3/3 Loss: 1.356570\n",
      "Epoch    9/20 Batch 1/3 Loss: 2.764643\n",
      "Epoch    9/20 Batch 2/3 Loss: 2.375928\n",
      "Epoch    9/20 Batch 3/3 Loss: 0.011790\n",
      "Epoch   10/20 Batch 1/3 Loss: 1.922008\n",
      "Epoch   10/20 Batch 2/3 Loss: 2.681981\n",
      "Epoch   10/20 Batch 3/3 Loss: 3.026026\n",
      "Epoch   11/20 Batch 1/3 Loss: 3.375723\n",
      "Epoch   11/20 Batch 2/3 Loss: 1.065328\n",
      "Epoch   11/20 Batch 3/3 Loss: 3.271287\n",
      "Epoch   12/20 Batch 1/3 Loss: 3.600816\n",
      "Epoch   12/20 Batch 2/3 Loss: 0.863791\n",
      "Epoch   12/20 Batch 3/3 Loss: 2.271934\n",
      "Epoch   13/20 Batch 1/3 Loss: 2.999619\n",
      "Epoch   13/20 Batch 2/3 Loss: 1.908337\n",
      "Epoch   13/20 Batch 3/3 Loss: 0.057925\n",
      "Epoch   14/20 Batch 1/3 Loss: 0.611614\n",
      "Epoch   14/20 Batch 2/3 Loss: 2.691003\n",
      "Epoch   14/20 Batch 3/3 Loss: 3.622105\n",
      "Epoch   15/20 Batch 1/3 Loss: 0.756488\n",
      "Epoch   15/20 Batch 2/3 Loss: 4.043310\n",
      "Epoch   15/20 Batch 3/3 Loss: 3.869190\n",
      "Epoch   16/20 Batch 1/3 Loss: 2.849683\n",
      "Epoch   16/20 Batch 2/3 Loss: 1.993646\n",
      "Epoch   16/20 Batch 3/3 Loss: 2.935249\n",
      "Epoch   17/20 Batch 1/3 Loss: 1.876523\n",
      "Epoch   17/20 Batch 2/3 Loss: 2.214644\n",
      "Epoch   17/20 Batch 3/3 Loss: 6.566172\n",
      "Epoch   18/20 Batch 1/3 Loss: 2.001108\n",
      "Epoch   18/20 Batch 2/3 Loss: 3.042033\n",
      "Epoch   18/20 Batch 3/3 Loss: 1.271055\n",
      "Epoch   19/20 Batch 1/3 Loss: 2.225346\n",
      "Epoch   19/20 Batch 2/3 Loss: 2.966599\n",
      "Epoch   19/20 Batch 3/3 Loss: 0.000107\n",
      "Epoch   20/20 Batch 1/3 Loss: 2.217542\n",
      "Epoch   20/20 Batch 2/3 Loss: 1.603390\n",
      "Epoch   20/20 Batch 3/3 Loss: 3.881085\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs+1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x_train, y_train = samples\n",
    "        \n",
    "        prediction = model(x_train)\n",
    "        loss = F.mse_loss(prediction, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'Epoch {epoch:4d}/{epochs} Batch {batch_idx+1}/{len(dataloader)} Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b8ee820-f781-4337-981d-241301c3b58a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[153.2914]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d35eb7a-3caa-4bfc-b921-72e7fc018f49",
   "metadata": {},
   "source": [
    "## 3-3. Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942388cb-e3dd-408a-862f-7c71ff32da24",
   "metadata": {},
   "source": [
    "> `torch.utils.data.Dataset`을 상속받아 커스텀 데이터셋을 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a898e198-ec31-423e-a98f-6ff2302a0ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        # 데이터셋 전처리\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                       [93, 88, 93],\n",
    "                       [89, 91, 90],\n",
    "                       [96, 98, 100],\n",
    "                       [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # 데이터셋의 길이\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 데이터셋에서 특정 샘플을 가져오는 함수\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10e9802d-9c5c-4f83-9335-4c4a87cfcfb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
